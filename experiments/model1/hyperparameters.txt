#########################################################################################
#  Generator  Hyper-parameters
######################################################################################
EMB_DIM = 32 # embedding dimension
HIDDEN_DIM = 32 # hidden state dimension of lstm cell
SEQ_LENGTH = 20 # sequence length
START_TOKEN = 0
SEED = 88
BATCH_SIZE = 64

PRE_GEN_EPOCH_NUM = 120 # supervise (maximum likelihood estimation) epochs 120 -- > 1
PRE_DIS_EPOCH_NUM = 3   # 50 -> 1
IN_DIS_EPOCH = 2 # 3 -> 1
ADV_GEN_EPOCH_NUM = 2
ADV_DIS_EPOCH_NUM = 1 # 5 -> 1
#########################################################################################
#  Discriminator  Hyper-parameters
#########################################################################################
dis_embedding_dim = 64
dis_filter_sizes = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20]
dis_num_filters = [100, 200, 200, 200, 200, 100, 100, 100, 100, 100, 160, 160]
dis_dropout_keep_prob = 0.75
dis_l2_reg_lambda = 0.2
dis_batch_size = 64

#########################################################################################
#  Basic Training Parameters
#########################################################################################
TOTAL_BATCH = 200
positive_file = 'save/real_data.txt'
negative_file = 'save/generator_sample.txt'
## 用来保存分割句子的文件
positive_file_split = 'save/real_data.split.txt'
negative_file_split = 'save/generator_sample.split.txt'
eval_file = 'save/eval_file.txt'
generated_num = 10000
save_path = 'experiments/model1/'